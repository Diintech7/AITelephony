const WebSocket = require("ws")
require("dotenv").config()
const mongoose = require("mongoose")
const Agent = require("../models/Agent")
const CallLog = require("../models/CallLog")

// Load API keys from environment variables
const API_KEYS = {
  deepgram: process.env.DEEPGRAM_API_KEY,
  sarvam: process.env.SARVAM_API_KEY,
  openai: process.env.OPENAI_API_KEY,
}

// Validate API keys
if (!API_KEYS.deepgram || !API_KEYS.sarvam || !API_KEYS.openai) {
  console.error("‚ùå Missing required API keys in environment variables")
  process.exit(1)
}

const fetch = globalThis.fetch || require("node-fetch")

// Performance timing helper
const createTimer = (label) => {
  const start = Date.now()
  return {
    start,
    end: () => Date.now() - start,
    checkpoint: (checkpointName) => Date.now() - start,
  }
}

// SIP Header Decoder Utility (unchanged)
class SIPHeaderDecoder {
  static decodeBase64Extra(base64String) {
    try {
      const decoded = Buffer.from(base64String, "base64").toString("utf-8")
      const parsed = JSON.parse(decoded)

      console.log(`üîì [SIP-DECODE] Base64 decoded successfully`)
      console.log(`üìã [SIP-DECODE] Parsed data:`, JSON.stringify(parsed, null, 2))

      return parsed
    } catch (error) {
      console.error(`‚ùå [SIP-DECODE] Failed to decode base64 extra: ${error.message}`)
      return null
    }
  }

  static parseConnectionURL(url) {
    try {
      let fullUrl = url
      if (!url.startsWith("http") && !url.startsWith("ws")) {
        if (url.startsWith("/")) {
          fullUrl = "wss://dummy.com" + url
        } else {
          console.log(`‚ö†Ô∏è [SIP-PARSE] Invalid URL format: ${url}`)
          return null
        }
      }

      const urlObj = new URL(fullUrl)
      const params = new URLSearchParams(urlObj.search)

      const hasParams = params.has("app_id") || params.has("caller_id") || params.has("did") || params.has("extra")

      if (!hasParams) {
        console.log(`‚ÑπÔ∏è [SIP-PARSE] No SIP parameters found in URL: ${url}`)
        return null
      }

      const sipData = {
        app_id: params.get("app_id"),
        caller_id: params.get("caller_id"),
        did: params.get("did"),
        direction: params.get("direction"),
        session_id: params.get("session_id"),
        extra_raw: params.get("extra"),
        czdata: params.get("czdata"),
      }

      if (sipData.extra_raw) {
        try {
          const decodedExtra = this.decodeBase64Extra(decodeURIComponent(sipData.extra_raw))
          sipData.extra = decodedExtra
        } catch (decodeError) {
          console.error(`‚ùå [SIP-PARSE] Failed to decode extra field: ${decodeError.message}`)
          sipData.extra = null
        }
      }

      return sipData
    } catch (error) {
      console.log(`‚ÑπÔ∏è [SIP-PARSE] URL parsing failed (likely non-SIP connection): ${error.message}`)
      return null
    }
  }

  static logSIPData(sipData) {
    console.log(`\nüåê [SIP-HEADERS] ==========================================`)
    console.log(`üì± [SIP-HEADERS] Customer Mobile (caller_id): ${sipData.caller_id}`)
    console.log(`üìû [SIP-HEADERS] DID Number: ${sipData.did}`)
    console.log(`üîÑ [SIP-HEADERS] Direction: ${sipData.direction || "Not specified"}`)
    console.log(`üÜî [SIP-HEADERS] App ID: ${sipData.app_id}`)
    console.log(`üîó [SIP-HEADERS] Session ID: ${sipData.session_id}`)

    if (sipData.extra) {
      console.log(`üìã [SIP-HEADERS] Extra Data:`)
      console.log(`   ‚Ä¢ Call CLI: ${sipData.extra.CallCli}`)
      console.log(`   ‚Ä¢ Call Session ID: ${sipData.extra.CallSessionId}`)
      console.log(`   ‚Ä¢ Call VA ID: ${sipData.extra.CallVaId}`)
      console.log(`   ‚Ä¢ DID (from extra): ${sipData.extra.DID}`)
      console.log(`   ‚Ä¢ CZ Service App ID: ${sipData.extra.CZSERVICEAPPID}`)
      console.log(`   ‚Ä¢ Call Direction: ${sipData.extra.CallDirection}`)
    }
    console.log(`üåê [SIP-HEADERS] ==========================================\n`)
  }

  static determineCallType(sipData) {
    if (sipData.extra?.CallDirection) {
      const direction = sipData.extra.CallDirection.toLowerCase()
      if (direction === "outdial") return "outbound"
      if (direction === "indial") return "inbound"
    }

    if (sipData.direction) {
      const direction = sipData.direction.toLowerCase()
      if (direction === "outbound" || direction === "outdial") return "outbound"
      if (direction === "inbound" || direction === "indial") return "inbound"
    }

    if (sipData.extra?.CallVaId) {
      return "inbound"
    }

    return "unknown"
  }

  static getCustomerNumber(sipData) {
    if (sipData.extra?.CallCli) {
      return sipData.extra.CallCli
    }

    if (sipData.caller_id && sipData.caller_id !== sipData.extra?.CallVaId) {
      return sipData.caller_id
    }

    return null
  }

  static getAgentIdentifier(sipData) {
    const callType = this.determineCallType(sipData)

    if (callType === "outbound") {
      return sipData.extra?.CallVaId || sipData.caller_id
    } else {
      return sipData.app_id
    }
  }
}

// Enhanced language mappings
const LANGUAGE_MAPPING = {
  hi: "hi-IN",
  en: "en-IN",
  bn: "bn-IN",
  te: "te-IN",
  ta: "ta-IN",
  mr: "mr-IN",
  gu: "gu-IN",
  kn: "kn-IN",
  ml: "ml-IN",
  pa: "pa-IN",
  or: "or-IN",
  as: "as-IN",
  ur: "ur-IN",
}

const getSarvamLanguage = (detectedLang, defaultLang = "hi") => {
  const lang = detectedLang?.toLowerCase() || defaultLang
  return LANGUAGE_MAPPING[lang] || "hi-IN"
}

const getDeepgramLanguage = (detectedLang, defaultLang = "hi") => {
  const lang = detectedLang?.toLowerCase() || defaultLang
  if (lang === "hi") return "hi"
  if (lang === "en") return "en-IN"
  if (lang === "mr") return "mr"
  return lang
}

// Valid Sarvam voice options
const VALID_SARVAM_VOICES = ["meera", "pavithra", "arvind", "amol", "maya"]

const getValidSarvamVoice = (voiceSelection = "pavithra") => {
  if (VALID_SARVAM_VOICES.includes(voiceSelection)) {
    return voiceSelection
  }

  const voiceMapping = {
    "male-professional": "arvind",
    "female-professional": "pavithra",
    "male-friendly": "amol",
    "female-friendly": "maya",
    neutral: "pavithra",
    default: "pavithra",
  }

  return voiceMapping[voiceSelection] || "pavithra"
}

// Language detection with OpenAI
const detectLanguageWithOpenAI = async (text) => {
  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${API_KEYS.openai}`,
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [
          {
            role: "system",
            content: `You are a language detection expert. Analyze the given text and return ONLY the 2-letter language code (hi, en, bn, te, ta, mr, gu, kn, ml, pa, or, as, ur). 

Examples:
- "Hello, how are you?" ‚Üí en
- "‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?" ‚Üí hi
- "‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡ßá‡¶Æ‡¶® ‡¶Ü‡¶õ‡ßá‡¶®?" ‚Üí bn
- "‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æé‡Æ™‡Øç‡Æ™‡Æü‡Æø ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç?" ‚Üí ta
- "‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ï‡§∏‡•á ‡§Ü‡§π‡§æ‡§§?" ‚Üí mr
- "‡™§‡™Æ‡´á ‡™ï‡´á‡™Æ ‡™õ‡´ã?" ‚Üí gu

Return only the language code, nothing else.`,
          },
          {
            role: "user",
            content: text,
          },
        ],
        max_tokens: 10,
        temperature: 0.1,
      }),
    })

    if (!response.ok) {
      throw new Error(`Language detection failed: ${response.status}`)
    }

    const data = await response.json()
    const detectedLang = data.choices[0]?.message?.content?.trim().toLowerCase()

    const validLanguages = Object.keys(LANGUAGE_MAPPING)
    if (validLanguages.includes(detectedLang)) {
      console.log(`üîç [LANG-DETECT] Detected: "${detectedLang}" from text: "${text.substring(0, 50)}..."`)
      return detectedLang
    }

    console.log(`‚ö†Ô∏è [LANG-DETECT] Invalid language "${detectedLang}", defaulting to "hi"`)
    return "hi"
  } catch (error) {
    console.error(`‚ùå [LANG-DETECT] Error: ${error.message}`)
    return "hi"
  }
}

// Enhanced Call logging utility class
class CallLogger {
  constructor(clientId, sipData = null) {
    this.clientId = clientId
    this.sipData = sipData
    this.mobile = SIPHeaderDecoder.getCustomerNumber(sipData) || sipData?.caller_id || null
    this.callStartTime = new Date()
    this.transcripts = []
    this.responses = []
    this.totalDuration = 0

    if (sipData) {
      console.log(`üìù [CALL-LOG] Initialized with SIP data for client: ${clientId}`)
      console.log(`üì± [CALL-LOG] Customer number: ${this.mobile}`)
      SIPHeaderDecoder.logSIPData(sipData)
    }
  }

  logUserTranscript(transcript, language, timestamp = new Date()) {
    const entry = {
      type: "user",
      text: transcript,
      language: language,
      timestamp: timestamp,
      source: "deepgram",
    }

    this.transcripts.push(entry)
    console.log(`üìù [CALL-LOG] User: "${transcript}" (${language})`)
  }

  logAIResponse(response, language, timestamp = new Date()) {
    const entry = {
      type: "ai",
      text: response,
      language: language,
      timestamp: timestamp,
      source: "sarvam",
    }

    this.responses.push(entry)
    console.log(`ü§ñ [CALL-LOG] AI: "${response}" (${language})`)
  }

  generateFullTranscript() {
    const allEntries = [...this.transcripts, ...this.responses].sort(
      (a, b) => new Date(a.timestamp) - new Date(b.timestamp),
    )

    return allEntries
      .map((entry) => {
        const speaker = entry.type === "user" ? "User" : "AI"
        const time = entry.timestamp.toISOString()
        return `[${time}] ${speaker} (${entry.language}): ${entry.text}`
      })
      .join("\n")
  }

  async saveToDatabase(leadStatus = "medium") {
    try {
      const callEndTime = new Date()
      this.totalDuration = Math.round((callEndTime - this.callStartTime) / 1000)

      const callLogData = {
        clientId: this.clientId,
        mobile: this.mobile,
        time: this.callStartTime,
        transcript: this.generateFullTranscript(),
        duration: this.totalDuration,
        leadStatus: leadStatus,
        metadata: {
          userTranscriptCount: this.transcripts.length,
          aiResponseCount: this.responses.length,
          languages: [...new Set([...this.transcripts, ...this.responses].map((entry) => entry.language))],
          callEndTime: callEndTime,
          sipData: this.sipData,
          callType: this.sipData ? SIPHeaderDecoder.determineCallType(this.sipData) : "unknown",
          did: this.sipData?.did,
          appId: this.sipData?.app_id,
          sessionId: this.sipData?.session_id,
          extraData: this.sipData?.extra,
          customerNumber: this.mobile,
        },
      }

      const callLog = new CallLog(callLogData)
      const savedLog = await callLog.save()

      console.log(`üíæ [CALL-LOG] Saved to DB - ID: ${savedLog._id}, Duration: ${this.totalDuration}s`)
      console.log(
        `üìä [CALL-LOG] Stats - User messages: ${this.transcripts.length}, AI responses: ${this.responses.length}`,
      )

      if (this.sipData) {
        console.log(
          `üìû [CALL-LOG] SIP Data - Type: ${SIPHeaderDecoder.determineCallType(this.sipData)}, DID: ${this.sipData.did}, Customer: ${this.mobile}`,
        )
      }

      return savedLog
    } catch (error) {
      console.error(`‚ùå [CALL-LOG] Database save error: ${error.message}`)
      throw error
    }
  }

  getStats() {
    return {
      duration: this.totalDuration,
      userMessages: this.transcripts.length,
      aiResponses: this.responses.length,
      languages: [...new Set([...this.transcripts, ...this.responses].map((entry) => entry.language))],
      startTime: this.callStartTime,
      sipData: this.sipData,
      callType: this.sipData ? SIPHeaderDecoder.determineCallType(this.sipData) : "unknown",
      customerNumber: this.mobile,
    }
  }
}

// OPTIMIZED: Persistent Deepgram Connection Manager
class PersistentDeepgramManager {
  constructor(language, onTranscript, onError, customerNumber) {
    this.language = language
    this.onTranscript = onTranscript
    this.onError = onError
    this.customerNumber = customerNumber
    this.deepgramWs = null
    this.isConnected = false
    this.audioQueue = []
    this.reconnectAttempts = 0
    this.maxReconnectAttempts = 3
    this.reconnectDelay = 1000 // Start with 1 second
    this.connectionTimer = null
    this.lastActivity = Date.now()
    this.keepAliveInterval = null
  }

  async connect() {
    if (this.deepgramWs && this.isConnected) {
      console.log(`‚úÖ [DEEPGRAM-PERSISTENT] Already connected for ${this.customerNumber}`)
      return true
    }

    try {
      console.log(
        `üîå [DEEPGRAM-PERSISTENT] Connecting for ${this.customerNumber} (attempt ${this.reconnectAttempts + 1})`,
      )

      const deepgramLanguage = getDeepgramLanguage(this.language)
      console.log(`üåç [DEEPGRAM-PERSISTENT] Using language: ${deepgramLanguage}`)

      const deepgramUrl = new URL("wss://api.deepgram.com/v1/listen")
      deepgramUrl.searchParams.append("sample_rate", "8000")
      deepgramUrl.searchParams.append("channels", "1")
      deepgramUrl.searchParams.append("encoding", "linear16")
      deepgramUrl.searchParams.append("model", "nova-2")
      deepgramUrl.searchParams.append("language", deepgramLanguage)
      deepgramUrl.searchParams.append("interim_results", "true")
      deepgramUrl.searchParams.append("smart_format", "true")
      deepgramUrl.searchParams.append("endpointing", "300")
      deepgramUrl.searchParams.append("keep_alive", "true") // Keep connection alive

      this.deepgramWs = new WebSocket(deepgramUrl.toString(), {
        headers: {
          Authorization: `Token ${API_KEYS.deepgram}`,
          "User-Agent": `VoiceServer/1.0 Customer-${this.customerNumber}`,
        },
      })

      return new Promise((resolve, reject) => {
        const connectionTimeout = setTimeout(() => {
          console.error(`‚ùå [DEEPGRAM-PERSISTENT] Connection timeout for ${this.customerNumber}`)
          this.cleanup()
          reject(new Error("Connection timeout"))
        }, 10000) // 10 second timeout

        this.deepgramWs.onopen = () => {
          clearTimeout(connectionTimeout)
          this.isConnected = true
          this.reconnectAttempts = 0
          this.reconnectDelay = 1000 // Reset delay
          this.lastActivity = Date.now()

          console.log(`‚úÖ [DEEPGRAM-PERSISTENT] Connected successfully for ${this.customerNumber}`)

          // Process queued audio
          if (this.audioQueue.length > 0) {
            console.log(`üì¶ [DEEPGRAM-PERSISTENT] Processing ${this.audioQueue.length} queued audio buffers`)
            this.audioQueue.forEach((buffer, index) => {
              this.deepgramWs.send(buffer)
              console.log(`üì§ [DEEPGRAM-PERSISTENT] Sent queued buffer ${index + 1}/${this.audioQueue.length}`)
            })
            this.audioQueue = []
          }

          // Start keep-alive mechanism
          this.startKeepAlive()

          resolve(true)
        }

        this.deepgramWs.onmessage = (event) => {
          this.lastActivity = Date.now()
          const data = JSON.parse(event.data)
          this.handleMessage(data)
        }

        this.deepgramWs.onerror = (error) => {
          clearTimeout(connectionTimeout)
          console.error(`‚ùå [DEEPGRAM-PERSISTENT] WebSocket error for ${this.customerNumber}:`, error)
          this.isConnected = false

          if (this.onError) {
            this.onError(error)
          }

          reject(error)
        }

        this.deepgramWs.onclose = (event) => {
          clearTimeout(connectionTimeout)
          console.log(
            `üîå [DEEPGRAM-PERSISTENT] Connection closed for ${this.customerNumber} - Code: ${event.code}, Reason: ${event.reason}`,
          )
          this.isConnected = false
          this.stopKeepAlive()

          // Auto-reconnect logic for unexpected closures
          if (event.code !== 1000 && this.reconnectAttempts < this.maxReconnectAttempts) {
            console.log(
              `üîÑ [DEEPGRAM-PERSISTENT] Attempting reconnection for ${this.customerNumber} in ${this.reconnectDelay}ms`,
            )
            setTimeout(() => {
              this.reconnectAttempts++
              this.reconnectDelay *= 2 // Exponential backoff
              this.connect().catch((err) => {
                console.error(`‚ùå [DEEPGRAM-PERSISTENT] Reconnection failed for ${this.customerNumber}:`, err.message)
              })
            }, this.reconnectDelay)
          }

          if (this.reconnectAttempts >= this.maxReconnectAttempts) {
            console.error(`‚ùå [DEEPGRAM-PERSISTENT] Max reconnection attempts reached for ${this.customerNumber}`)
          }
        }
      })
    } catch (error) {
      console.error(`‚ùå [DEEPGRAM-PERSISTENT] Setup error for ${this.customerNumber}: ${error.message}`)
      throw error
    }
  }

  startKeepAlive() {
    // Send keep-alive messages every 30 seconds
    this.keepAliveInterval = setInterval(() => {
      if (this.isConnected && this.deepgramWs && this.deepgramWs.readyState === WebSocket.OPEN) {
        // Check if connection has been idle for too long
        const idleTime = Date.now() - this.lastActivity
        if (idleTime > 60000) {
          // 1 minute idle
          console.log(
            `üíì [DEEPGRAM-KEEP-ALIVE] Sending keep-alive for ${this.customerNumber} (idle: ${Math.round(idleTime / 1000)}s)`,
          )

          // Send a small keep-alive message
          const keepAliveMessage = {
            type: "KeepAlive",
            timestamp: Date.now(),
          }

          try {
            this.deepgramWs.send(JSON.stringify(keepAliveMessage))
            this.lastActivity = Date.now()
          } catch (error) {
            console.error(
              `‚ùå [DEEPGRAM-KEEP-ALIVE] Failed to send keep-alive for ${this.customerNumber}:`,
              error.message,
            )
          }
        }
      }
    }, 30000)
  }

  stopKeepAlive() {
    if (this.keepAliveInterval) {
      clearInterval(this.keepAliveInterval)
      this.keepAliveInterval = null
    }
  }

  handleMessage(data) {
    if (data.type === "Results") {
      const transcript = data.channel?.alternatives?.[0]?.transcript
      const is_final = data.is_final
      const confidence = data.channel?.alternatives?.[0]?.confidence

      if (transcript?.trim()) {
        console.log(
          `üé§ [DEEPGRAM-PERSISTENT] ${is_final ? "FINAL" : "interim"} from ${this.customerNumber}: "${transcript}" (confidence: ${confidence || "unknown"})`,
        )

        if (this.onTranscript) {
          this.onTranscript(transcript, is_final, confidence)
        }
      }
    } else if (data.type === "UtteranceEnd") {
      console.log(`üîö [DEEPGRAM-PERSISTENT] Utterance end for ${this.customerNumber}`)
      if (this.onTranscript) {
        this.onTranscript(null, true, null, "utterance_end")
      }
    } else if (data.type === "Metadata") {
      console.log(`üìä [DEEPGRAM-PERSISTENT] Metadata for ${this.customerNumber}:`, {
        request_id: data.request_id,
        model_info: data.model_info,
      })
    }
  }

  sendAudio(audioBuffer) {
    if (this.isConnected && this.deepgramWs && this.deepgramWs.readyState === WebSocket.OPEN) {
      try {
        this.deepgramWs.send(audioBuffer)
        this.lastActivity = Date.now()
        console.log(`üì§ [DEEPGRAM-PERSISTENT] Sent ${audioBuffer.length} bytes for ${this.customerNumber}`)
        return true
      } catch (error) {
        console.error(`‚ùå [DEEPGRAM-PERSISTENT] Error sending audio for ${this.customerNumber}:`, error.message)
        this.isConnected = false
        return false
      }
    } else {
      // Queue audio if not connected
      this.audioQueue.push(audioBuffer)
      console.log(
        `üì¶ [DEEPGRAM-PERSISTENT] Queued ${audioBuffer.length} bytes for ${this.customerNumber} (queue size: ${this.audioQueue.length})`,
      )

      // Try to reconnect if not connected
      if (!this.isConnected) {
        this.connect().catch((error) => {
          console.error(`‚ùå [DEEPGRAM-PERSISTENT] Auto-reconnect failed for ${this.customerNumber}:`, error.message)
        })
      }

      return false
    }
  }

  updateLanguage(newLanguage) {
    if (newLanguage !== this.language) {
      console.log(
        `üîÑ [DEEPGRAM-PERSISTENT] Language change for ${this.customerNumber}: ${this.language} ‚Üí ${newLanguage}`,
      )
      this.language = newLanguage

      // Reconnect with new language
      this.disconnect()
      this.connect().catch((error) => {
        console.error(
          `‚ùå [DEEPGRAM-PERSISTENT] Language update reconnection failed for ${this.customerNumber}:`,
          error.message,
        )
      })
    }
  }

  disconnect() {
    console.log(`üîå [DEEPGRAM-PERSISTENT] Disconnecting for ${this.customerNumber}`)

    this.stopKeepAlive()

    if (this.deepgramWs) {
      if (this.deepgramWs.readyState === WebSocket.OPEN) {
        this.deepgramWs.close(1000, "Normal closure")
      }
      this.deepgramWs = null
    }

    this.isConnected = false
    this.audioQueue = []
  }

  cleanup() {
    this.disconnect()
    this.onTranscript = null
    this.onError = null
  }

  getStatus() {
    return {
      isConnected: this.isConnected,
      language: this.language,
      queueSize: this.audioQueue.length,
      reconnectAttempts: this.reconnectAttempts,
      lastActivity: this.lastActivity,
      customerNumber: this.customerNumber,
    }
  }
}

// OpenAI streaming processing (unchanged)
const processWithOpenAIStreaming = async (
  userMessage,
  conversationHistory,
  detectedLanguage,
  onPhrase,
  onComplete,
  onInterrupt,
  callLogger,
) => {
  const timer = createTimer("OPENAI_STREAMING")

  try {
    const getSystemPrompt = (lang) => {
      const prompts = {
        hi: "‡§Ü‡§™ ‡§è‡§Ü‡§à ‡§§‡•ã‡§§‡§æ ‡§π‡•à‡§Ç, ‡§è‡§ï ‡§µ‡§ø‡§®‡§Æ‡•ç‡§∞ ‡§î‡§∞ ‡§≠‡§æ‡§µ‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® AI ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§∏‡•á‡§µ‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä‡•§ ‡§Ü‡§™ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ß‡§æ‡§∞‡§æ‡§™‡•ç‡§∞‡§µ‡§æ‡§π ‡§¨‡•ã‡§≤‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï, ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç ‡§ú‡•ã ‡§ó‡§∞‡•ç‡§Æ‡§ú‡•ã‡§∂‡•Ä ‡§î‡§∞ ‡§∏‡§π‡§æ‡§®‡•Å‡§≠‡•Ç‡§§‡§ø ‡§∏‡•á ‡§≠‡§∞‡•Ä ‡§π‡•ã‡•§ ‡§ú‡§µ‡§æ‡§¨ ‡§õ‡•ã‡§ü‡•á ‡§∞‡§ñ‡•á‡§Ç‚Äî‡§ï‡•á‡§µ‡§≤ 1-2 ‡§≤‡§æ‡§á‡§®‡•§ ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•Å‡§®‡§æ, ‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§î‡§∞ ‡§Æ‡•Ç‡§≤‡•ç‡§Ø‡§µ‡§æ‡§® ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞‡§æ‡§®‡§æ ‡§Ü‡§™‡§ï‡§æ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø ‡§π‡•à‡•§",

        en: "You are Aitota, a polite, emotionally intelligent AI customer care executive. You speak fluently in English. Use natural, conversational language with warmth and empathy. Keep responses short‚Äîjust 1‚Äì2 lines. Your goal is to make customers feel heard, supported, and valued.",

        bn: "‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ü‡¶á‡¶§‡ßã‡¶§‡¶æ, ‡¶è‡¶ï‡¶ú‡¶® ‡¶≠‡¶¶‡ßç‡¶∞ ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶¨‡ßá‡¶ó‡¶™‡ßç‡¶∞‡¶¨‡¶£‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡ßÅ‡¶¶‡ßç‡¶ß‡¶ø‡¶Æ‡¶æ‡¶® AI ‡¶ó‡ßç‡¶∞‡¶æ‡¶π‡¶ï ‡¶∏‡ßá‡¶¨‡¶æ ‡¶ï‡¶∞‡ßç‡¶Æ‡¶ï‡¶∞‡ßç‡¶§‡¶æ‡•§ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶∏‡¶æ‡¶¨‡¶≤‡ßÄ‡¶≤‡¶≠‡¶æ‡¶¨‡ßá ‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßá‡¶®‡•§ ‡¶â‡¶∑‡ßç‡¶£‡¶§‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶π‡¶æ‡¶®‡ßÅ‡¶≠‡ßÇ‡¶§‡¶ø ‡¶∏‡¶π ‡¶™‡ßç‡¶∞‡¶æ‡¶ï‡ßÉ‡¶§‡¶ø‡¶ï, ‡¶ï‡¶•‡ßã‡¶™‡¶ï‡¶•‡¶®‡¶Æ‡ßÇ‡¶≤‡¶ï ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§",

        te: "‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ê‡∞§‡±ã‡∞§‡∞æ, ‡∞Æ‡∞∞‡±ç‡∞Ø‡∞æ‡∞¶‡∞™‡±Ç‡∞∞‡±ç‡∞µ‡∞ï, ‡∞≠‡∞æ‡∞µ‡±ã‡∞¶‡±ç‡∞µ‡±á‡∞ó‡∞Ç‡∞§‡±ã ‡∞§‡±Ü‡∞≤‡∞ø‡∞µ‡±à‡∞® AI ‡∞ï‡∞∏‡±ç‡∞ü‡∞Æ‡∞∞‡±ç ‡∞ï‡±á‡∞∞‡±ç ‡∞é‡∞ó‡±ç‡∞ú‡∞ø‡∞ï‡±ç‡∞Ø‡±Ç‡∞ü‡∞ø‡∞µ‡±ç. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞∏‡∞∞‡∞≥‡∞Ç‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡±Å‡∞§‡∞æ‡∞∞‡±Å‡•§ ‡∞µ‡±Ü‡∞ö‡±ç‡∞ö‡∞¶‡∞®‡∞Ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞∏‡∞æ‡∞®‡±Å‡∞≠‡±Ç‡∞§‡∞ø‡∞§‡±ã ‡∞∏‡∞π‡∞ú‡∞Æ‡±à‡∞®, ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£‡∞æ ‡∞≠‡∞æ‡∞∑‡∞®‡±Å ‡∞â‡∞™‡∞Ø‡±ã‡∞ó‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø‡•§",

        ta: "‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æê‡Æ§‡Øã‡Æ§‡Ææ, ‡Æí‡Æ∞‡ØÅ ‡Æï‡Æ£‡Øç‡Æ£‡Æø‡ÆØ‡ÆÆ‡Ææ‡Æ©, ‡Æâ‡Æ£‡Æ∞‡Øç‡Æµ‡ØÅ‡Æ™‡ØÇ‡Æ∞‡Øç‡Æµ‡ÆÆ‡Ææ‡Æï ‡Æ™‡ØÅ‡Æ§‡Øç‡Æ§‡Æø‡Æö‡Ææ‡Æ≤‡Æø‡Æ§‡Øç‡Æ§‡Æ©‡ÆÆ‡Ææ‡Æ© AI ‡Æµ‡Ææ‡Æü‡Æø‡Æï‡Øç‡Æï‡Øà‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç ‡Æö‡Øá‡Æµ‡Øà ‡Æ®‡Æø‡Æ∞‡Øç‡Æµ‡Ææ‡Æï‡Æø. ‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Æø‡Æ≤‡Øç ‡Æö‡Æ∞‡Æ≥‡ÆÆ‡Ææ‡Æï ‡Æ™‡Øá‡Æö‡ØÅ‡Æï‡Æø‡Æ±‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç. ‡ÆÖ‡Æ©‡Øç‡Æ™‡ØÅ ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ©‡ØÅ‡Æ§‡Ææ‡Æ™‡Æ§‡Øç‡Æ§‡ØÅ‡Æü‡Æ©‡Øç ‡Æá‡ÆØ‡Æ±‡Øç‡Æï‡Øà‡ÆØ‡Ææ‡Æ©, ‡Æâ‡Æ∞‡Øà‡ÆØ‡Ææ‡Æü‡Æ≤‡Øç ‡ÆÆ‡Øä‡Æ¥‡Æø‡ÆØ‡Øà‡Æ™‡Øç ‡Æ™‡ÆØ‡Æ©‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç‡•§",

        mr: "‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§è‡§Ü‡§Ø‡§§‡•ã‡§§‡§æ ‡§Ü‡§π‡§æ‡§§, ‡§è‡§ï ‡§®‡§Æ‡•ç‡§∞ ‡§Ü‡§£‡§ø ‡§≠‡§æ‡§µ‡§®‡§ø‡§ï‡§¶‡•É‡§∑‡•ç‡§ü‡•ç‡§Ø‡§æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§® AI ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï ‡§∏‡•á‡§µ‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä. ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§Ö‡§∏‡•ç‡§ñ‡§≤‡§ø‡§§‡§™‡§£‡•á ‡§¨‡•ã‡§≤‡§§‡§æ. ‡§â‡§¨‡§¶‡§æ‡§∞‡§™‡§£‡§æ ‡§Ü‡§£‡§ø ‡§∏‡§π‡§æ‡§®‡•Å‡§≠‡•Ç‡§§‡•Ä‡§∏‡§π ‡§®‡•à‡§∏‡§∞‡•ç‡§ó‡§ø‡§ï, ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§§‡•ç‡§Æ‡§ï ‡§≠‡§æ‡§∑‡§æ ‡§µ‡§æ‡§™‡§∞‡§æ. ‡§â‡§§‡•ç‡§§‡§∞‡•á ‡§≤‡§π‡§æ‡§® ‡§†‡•á‡§µ‡§æ‚Äî‡§´‡§ï‡•ç‡§§ 1-2 ‡§ì‡§≥‡•Ä. ‡§ó‡•ç‡§∞‡§æ‡§π‡§ï‡§æ‡§Ç‡§®‡§æ ‡§ê‡§ï‡§≤‡•á, ‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§Ü‡§£‡§ø ‡§Æ‡•Ç‡§≤‡•ç‡§Ø‡§µ‡§æ‡§® ‡§µ‡§æ‡§ü‡§£‡•ç‡§Ø‡§æ‡§ö‡•á ‡§§‡•Å‡§Æ‡§ö‡•á ‡§ß‡•ç‡§Ø‡•á‡§Ø ‡§Ü‡§π‡•á‡•§",
      }

      return prompts[lang] || prompts.en
    }

    const systemPrompt = getSystemPrompt(detectedLanguage)

    const messages = [
      { role: "system", content: systemPrompt },
      ...conversationHistory.slice(-6),
      { role: "user", content: userMessage },
    ]

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${API_KEYS.openai}`,
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages,
        max_tokens: 80,
        temperature: 0.3,
        stream: true,
      }),
    })

    if (!response.ok) {
      console.error(`‚ùå [OPENAI] Error: ${response.status}`)
      return null
    }

    let fullResponse = ""
    let phraseBuffer = ""
    let isFirstPhrase = true
    let isInterrupted = false

    const reader = response.body.getReader()
    const decoder = new TextDecoder()

    const checkInterruption = () => {
      return onInterrupt && onInterrupt()
    }

    while (true) {
      if (checkInterruption()) {
        isInterrupted = true
        console.log(`‚ö†Ô∏è [OPENAI] Stream interrupted by new user input`)
        reader.cancel()
        break
      }

      const { done, value } = await reader.read()
      if (done) break

      const chunk = decoder.decode(value, { stream: true })
      const lines = chunk.split("\n").filter((line) => line.trim())

      for (const line of lines) {
        if (line.startsWith("data: ")) {
          const data = line.slice(6)

          if (data === "[DONE]") {
            if (phraseBuffer.trim() && !isInterrupted) {
              onPhrase(phraseBuffer.trim(), detectedLanguage)
              fullResponse += phraseBuffer
            }
            break
          }

          try {
            const parsed = JSON.parse(data)
            const content = parsed.choices?.[0]?.delta?.content

            if (content) {
              phraseBuffer += content

              if (checkInterruption()) {
                isInterrupted = true
                break
              }

              if (shouldSendPhrase(phraseBuffer)) {
                const phrase = phraseBuffer.trim()
                if (phrase.length > 0 && !isInterrupted) {
                  if (isFirstPhrase) {
                    console.log(`‚ö° [OPENAI] First phrase (${timer.checkpoint("first_phrase")}ms)`)
                    isFirstPhrase = false
                  }
                  onPhrase(phrase, detectedLanguage)
                  fullResponse += phrase
                  phraseBuffer = ""
                }
              }
            }
          } catch (e) {
            // Skip malformed JSON
          }
        }
      }

      if (isInterrupted) break
    }

    if (!isInterrupted) {
      console.log(`ü§ñ [OPENAI] Complete: "${fullResponse}" (${timer.end()}ms)`)

      if (callLogger && fullResponse.trim()) {
        callLogger.logAIResponse(fullResponse.trim(), detectedLanguage)
      }

      onComplete(fullResponse)
    } else {
      console.log(`ü§ñ [OPENAI] Interrupted after ${timer.end()}ms`)
    }

    return isInterrupted ? null : fullResponse
  } catch (error) {
    console.error(`‚ùå [OPENAI] Error: ${error.message}`)
    return null
  }
}

const shouldSendPhrase = (buffer) => {
  const trimmed = buffer.trim()

  if (/[.!?‡•§‡••‡•§]$/.test(trimmed)) return true
  if (trimmed.length >= 8 && /[,;‡•§]\s*$/.test(trimmed)) return true
  if (trimmed.length >= 25 && /\s/.test(trimmed)) return true

  return false
}

// TTS processor (unchanged)
class OptimizedSarvamTTSProcessor {
  constructor(language, ws, streamSid, callLogger = null) {
    this.language = language
    this.ws = ws
    this.streamSid = streamSid
    this.callLogger = callLogger
    this.queue = []
    this.isProcessing = false
    this.sarvamLanguage = getSarvamLanguage(language)
    this.voice = getValidSarvamVoice(ws.sessionAgentConfig?.voiceSelection || "pavithra")

    this.isInterrupted = false
    this.currentAudioStreaming = null

    this.sentenceBuffer = ""
    this.processingTimeout = 100
    this.sentenceTimer = null

    this.totalChunks = 0
    this.totalAudioBytes = 0
  }

  interrupt() {
    console.log(`‚ö†Ô∏è [SARVAM-TTS] Interrupting current processing`)
    this.isInterrupted = true

    this.queue = []
    this.sentenceBuffer = ""

    if (this.sentenceTimer) {
      clearTimeout(this.sentenceTimer)
      this.sentenceTimer = null
    }

    if (this.currentAudioStreaming) {
      this.currentAudioStreaming.interrupt = true
    }

    console.log(`üõë [SARVAM-TTS] Processing interrupted and cleaned up`)
  }

  reset(newLanguage) {
    this.interrupt()

    if (newLanguage) {
      this.language = newLanguage
      this.sarvamLanguage = getSarvamLanguage(newLanguage)
      console.log(`üîÑ [SARVAM-TTS] Language updated to: ${this.sarvamLanguage}`)
    }

    this.isInterrupted = false
    this.isProcessing = false
    this.totalChunks = 0
    this.totalAudioBytes = 0
  }

  addPhrase(phrase, detectedLanguage) {
    if (!phrase.trim() || this.isInterrupted) return

    if (detectedLanguage && detectedLanguage !== this.language) {
      console.log(`üîÑ [SARVAM-TTS] Language change detected: ${this.language} ‚Üí ${detectedLanguage}`)
      this.language = detectedLanguage
      this.sarvamLanguage = getSarvamLanguage(detectedLanguage)
    }

    this.sentenceBuffer += (this.sentenceBuffer ? " " : "") + phrase.trim()

    if (this.hasCompleteSentence(this.sentenceBuffer)) {
      this.processCompleteSentences()
    } else {
      this.scheduleProcessing()
    }
  }

  hasCompleteSentence(text) {
    return /[.!?‡•§‡••‡•§]/.test(text)
  }

  extractCompleteSentences(text) {
    const sentences = text.split(/([.!?‡•§‡••‡•§])/).filter((s) => s.trim())

    let completeSentences = ""
    let remainingText = ""

    for (let i = 0; i < sentences.length; i += 2) {
      const sentence = sentences[i]
      const punctuation = sentences[i + 1]

      if (punctuation) {
        completeSentences += sentence + punctuation + " "
      } else {
        remainingText = sentence
      }
    }

    return {
      complete: completeSentences.trim(),
      remaining: remainingText.trim(),
    }
  }

  processCompleteSentences() {
    if (this.isInterrupted) return

    if (this.sentenceTimer) {
      clearTimeout(this.sentenceTimer)
      this.sentenceTimer = null
    }

    const { complete, remaining } = this.extractCompleteSentences(this.sentenceBuffer)

    if (complete && !this.isInterrupted) {
      this.queue.push(complete)
      this.sentenceBuffer = remaining
      this.processQueue()
    }
  }

  scheduleProcessing() {
    if (this.isInterrupted) return

    if (this.sentenceTimer) clearTimeout(this.sentenceTimer)

    this.sentenceTimer = setTimeout(() => {
      if (this.sentenceBuffer.trim() && !this.isInterrupted) {
        this.queue.push(this.sentenceBuffer.trim())
        this.sentenceBuffer = ""
        this.processQueue()
      }
    }, this.processingTimeout)
  }

  async processQueue() {
    if (this.isProcessing || this.queue.length === 0 || this.isInterrupted) return

    this.isProcessing = true
    const textToProcess = this.queue.shift()

    try {
      if (!this.isInterrupted) {
        await this.synthesizeAndStream(textToProcess)
      }
    } catch (error) {
      if (!this.isInterrupted) {
        console.error(`‚ùå [SARVAM-TTS] Error: ${error.message}`)
      }
    } finally {
      this.isProcessing = false

      if (this.queue.length > 0 && !this.isInterrupted) {
        setTimeout(() => this.processQueue(), 10)
      }
    }
  }

  async synthesizeAndStream(text) {
    if (this.isInterrupted) return

    const timer = createTimer("SARVAM_TTS_SENTENCE")

    try {
      console.log(`üéµ [SARVAM-TTS] Synthesizing: "${text}" (${this.sarvamLanguage})`)

      const response = await fetch("https://api.sarvam.ai/text-to-speech", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "API-Subscription-Key": API_KEYS.sarvam,
        },
        body: JSON.stringify({
          inputs: [text],
          target_language_code: this.sarvamLanguage,
          speaker: this.voice,
          pitch: 0,
          pace: 1.0,
          loudness: 1.0,
          speech_sample_rate: 8000,
          enable_preprocessing: false,
          model: "bulbul:v1",
        }),
      })

      if (!response.ok || this.isInterrupted) {
        if (this.isInterrupted) return
        throw new Error(`Sarvam API error: ${response.status} - ${response.statusText}`)
      }

      const responseData = await response.json()
      const audioBase64 = responseData.audios?.[0]

      if (!audioBase64 || this.isInterrupted) {
        if (!this.isInterrupted) {
          throw new Error("No audio data received from Sarvam API")
        }
        return
      }

      console.log(`‚ö° [SARVAM-TTS] Synthesis completed in ${timer.end()}ms`)

      if (!this.isInterrupted) {
        await this.streamAudioOptimizedForSIP(audioBase64)

        const audioBuffer = Buffer.from(audioBase64, "base64")
        this.totalAudioBytes += audioBuffer.length
        this.totalChunks++
      }
    } catch (error) {
      if (!this.isInterrupted) {
        console.error(`‚ùå [SARVAM-TTS] Synthesis error: ${error.message}`)
        throw error
      }
    }
  }

  async streamAudioOptimizedForSIP(audioBase64) {
    if (this.isInterrupted) return

    const audioBuffer = Buffer.from(audioBase64, "base64")
    const streamingSession = { interrupt: false }
    this.currentAudioStreaming = streamingSession

    const SAMPLE_RATE = 8000
    const BYTES_PER_SAMPLE = 2
    const BYTES_PER_MS = (SAMPLE_RATE * BYTES_PER_SAMPLE) / 1000
    const OPTIMAL_CHUNK_SIZE = Math.floor(40 * BYTES_PER_MS)

    console.log(`üì¶ [SARVAM-SIP] Streaming ${audioBuffer.length} bytes`)

    let position = 0
    let chunkIndex = 0

    while (position < audioBuffer.length && !this.isInterrupted && !streamingSession.interrupt) {
      const remaining = audioBuffer.length - position
      const chunkSize = Math.min(OPTIMAL_CHUNK_SIZE, remaining)
      const chunk = audioBuffer.slice(position, position + chunkSize)

      console.log(`üì§ [SARVAM-SIP] Chunk ${chunkIndex + 1}: ${chunk.length} bytes`)

      const mediaMessage = {
        event: "media",
        streamSid: this.streamSid,
        media: {
          payload: chunk.toString("base64"),
        },
      }

      if (this.ws.readyState === WebSocket.OPEN && !this.isInterrupted) {
        this.ws.send(JSON.stringify(mediaMessage))
      }

      if (position + chunkSize < audioBuffer.length && !this.isInterrupted) {
        const chunkDurationMs = Math.floor(chunk.length / BYTES_PER_MS)
        const delayMs = Math.max(chunkDurationMs - 2, 10)
        await new Promise((resolve) => setTimeout(resolve, delayMs))
      }

      position += chunkSize
      chunkIndex++
    }

    if (this.isInterrupted || streamingSession.interrupt) {
      console.log(`üõë [SARVAM-SIP] Audio streaming interrupted at chunk ${chunkIndex}`)
    } else {
      console.log(`‚úÖ [SARVAM-SIP] Completed streaming ${chunkIndex} chunks`)
    }

    this.currentAudioStreaming = null
  }

  complete() {
    if (this.isInterrupted) return

    if (this.sentenceBuffer.trim()) {
      this.queue.push(this.sentenceBuffer.trim())
      this.sentenceBuffer = ""
    }

    if (this.queue.length > 0) {
      this.processQueue()
    }

    console.log(`üìä [SARVAM-STATS] Total: ${this.totalChunks} sentences, ${this.totalAudioBytes} bytes`)
  }

  getStats() {
    return {
      totalChunks: this.totalChunks,
      totalAudioBytes: this.totalAudioBytes,
      avgBytesPerChunk: this.totalChunks > 0 ? Math.round(this.totalAudioBytes / this.totalChunks) : 0,
    }
  }
}

// Agent configuration fetcher (unchanged)
class AgentConfigFetcher {
  static async fetchAgentConfig(sipData) {
    const callType = SIPHeaderDecoder.determineCallType(sipData)
    const agentIdentifier = SIPHeaderDecoder.getAgentIdentifier(sipData)
    const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData)

    console.log(`\nüîç [AGENT-FETCH] ==========================================`)
    console.log(`üìû [AGENT-FETCH] Call Type: ${callType}`)
    console.log(`üÜî [AGENT-FETCH] Agent Identifier: ${agentIdentifier}`)
    console.log(`üì± [AGENT-FETCH] Customer Number: ${customerNumber}`)
    console.log(`üåê [AGENT-FETCH] SIP Data received:`, JSON.stringify(sipData, null, 2))

    let agentConfig = null

    try {
      if (callType === "outbound") {
        console.log(`üì§ [AGENT-FETCH] Searching for OUTBOUND agent with callerId: "${agentIdentifier}"`)
        console.log(`üîç [AGENT-FETCH] Database query: Agent.findOne({ callerId: "${agentIdentifier}" })`)

        agentConfig = await Agent.findOne({ callerId: agentIdentifier }).lean()

        if (!agentConfig) {
          console.error(`‚ùå [AGENT-FETCH] No outbound agent found for callerId: "${agentIdentifier}"`)

          try {
            const availableAgents = await Agent.find({}, { callerId: 1, agentName: 1, clientId: 1 }).lean()
            console.log(`üìä [AGENT-FETCH] Available agents in database:`)
            availableAgents.forEach((agent, index) => {
              console.log(
                `   ${index + 1}. Agent: "${agent.agentName}" | CallerId: "${agent.callerId}" | ClientId: "${agent.clientId}"`,
              )
            })

            const partialMatches = availableAgents.filter(
              (agent) => agent.callerId && agent.callerId.includes(agentIdentifier),
            )

            if (partialMatches.length > 0) {
              console.log(`üîç [AGENT-FETCH] Partial matches found:`)
              partialMatches.forEach((agent, index) => {
                console.log(`   ${index + 1}. Agent: "${agent.agentName}" | CallerId: "${agent.callerId}"`)
              })
            }
          } catch (debugError) {
            console.error(`‚ùå [AGENT-FETCH] Error fetching available agents: ${debugError.message}`)
          }

          return {
            success: false,
            error: `No outbound agent found for callerId: "${agentIdentifier}". Please check agent configuration.`,
            callType,
            agentIdentifier,
            customerNumber,
          }
        }

        console.log(`‚úÖ [AGENT-FETCH] OUTBOUND agent found successfully!`)
        console.log(`   üè∑Ô∏è  Agent Name: "${agentConfig.agentName}"`)
        console.log(`   üÜî Client ID: "${agentConfig.clientId}"`)
        console.log(`   üìû Caller ID: "${agentConfig.callerId}"`)
        console.log(`   üåç Language: "${agentConfig.language}"`)
        console.log(`   üéµ Voice: "${agentConfig.voiceSelection}"`)
        console.log(`   üìù Category: "${agentConfig.category}"`)
        console.log(`   üë§ Personality: "${agentConfig.personality}"`)
        console.log(`   üí¨ First Message: "${agentConfig.firstMessage}"`)
      } else {
        console.log(`üì• [AGENT-FETCH] Searching for INBOUND agent with accountSid: "${agentIdentifier}"`)
        console.log(`üîç [AGENT-FETCH] Database query: Agent.findOne({ accountSid: "${agentIdentifier}" })`)

        agentConfig = await Agent.findOne({ accountSid: agentIdentifier }).lean()

        if (!agentConfig) {
          console.error(`‚ùå [AGENT-FETCH] No inbound agent found for accountSid: "${agentIdentifier}"`)

          try {
            const availableAgents = await Agent.find({}, { accountSid: 1, agentName: 1, clientId: 1 }).lean()
            console.log(`üìä [AGENT-FETCH] Available agents in database:`)
            availableAgents.forEach((agent, index) => {
              console.log(
                `   ${index + 1}. Agent: "${agent.agentName}" | AccountSid: "${agent.accountSid}" | ClientId: "${agent.clientId}"`,
              )
            })

            const partialMatches = availableAgents.filter(
              (agent) => agent.accountSid && agent.accountSid.includes(agentIdentifier),
            )

            if (partialMatches.length > 0) {
              console.log(`üîç [AGENT-FETCH] Partial matches found:`)
              partialMatches.forEach((agent, index) => {
                console.log(`   ${index + 1}. Agent: "${agent.agentName}" | AccountSid: "${agent.accountSid}"`)
              })
            }
          } catch (debugError) {
            console.error(`‚ùå [AGENT-FETCH] Error fetching available agents: ${debugError.message}`)
          }

          return {
            success: false,
            error: `No inbound agent found for accountSid: "${agentIdentifier}". Please check agent configuration.`,
            callType,
            agentIdentifier,
            customerNumber,
          }
        }

        console.log(`‚úÖ [AGENT-FETCH] INBOUND agent found successfully!`)
        console.log(`   üè∑Ô∏è  Agent Name: "${agentConfig.agentName}"`)
        console.log(`   üÜî Client ID: "${agentConfig.clientId}"`)
        console.log(`   üè¢ Account SID: "${agentConfig.accountSid}"`)
        console.log(`   üåç Language: "${agentConfig.language}"`)
        console.log(`   üéµ Voice: "${agentConfig.voiceSelection}"`)
        console.log(`   üìù Category: "${agentConfig.category}"`)
        console.log(`   üë§ Personality: "${agentConfig.personality}"`)
        console.log(`   üí¨ First Message: "${agentConfig.firstMessage}"`)
      }

      console.log(`üìã [AGENT-FETCH] Complete agent configuration loaded:`)
      console.log(`   üéØ STT Selection: "${agentConfig.sttSelection}"`)
      console.log(`   üîä TTS Selection: "${agentConfig.ttsSelection}"`)
      console.log(`   ü§ñ LLM Selection: "${agentConfig.llmSelection}"`)
      console.log(`   üìÖ Created: ${agentConfig.createdAt}`)
      console.log(`   üîÑ Updated: ${agentConfig.updatedAt}`)

      if (agentConfig.systemPrompt) {
        console.log(`   üìù System Prompt: "${agentConfig.systemPrompt.substring(0, 100)}..."`)
      }

      if (agentConfig.audioBytes) {
        console.log(`   üéµ Audio Bytes Length: ${agentConfig.audioBytes.length} characters`)
      }

      console.log(`üîç [AGENT-FETCH] ==========================================\n`)

      return {
        success: true,
        agentConfig,
        callType,
        agentIdentifier,
        customerNumber,
      }
    } catch (error) {
      console.error(`‚ùå [AGENT-FETCH] Database error: ${error.message}`)
      console.error(`‚ùå [AGENT-FETCH] Stack trace:`, error.stack)

      return {
        success: false,
        error: `Database error: ${error.message}`,
        callType,
        agentIdentifier,
        customerNumber,
      }
    }
  }

  static validateAgentConfig(agentConfig) {
    const requiredFields = ["clientId", "agentName", "language", "firstMessage"]
    const missingFields = []

    for (const field of requiredFields) {
      if (!agentConfig[field]) {
        missingFields.push(field)
      }
    }

    if (missingFields.length > 0) {
      console.warn(`‚ö†Ô∏è [AGENT-VALIDATION] Missing required fields: ${missingFields.join(", ")}`)
      return { valid: false, missingFields }
    }

    console.log(`‚úÖ [AGENT-VALIDATION] Agent configuration is valid`)
    return { valid: true, missingFields: [] }
  }

  static logCallerIdConnection(sipData, agentConfig) {
    const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData)
    const callType = SIPHeaderDecoder.determineCallType(sipData)
    const agentIdentifier = SIPHeaderDecoder.getAgentIdentifier(sipData)

    console.log(`\nüéØ [CALLER-ID-MATCH] ==========================================`)
    console.log(`üìû [CALLER-ID-MATCH] Call Type: ${callType}`)
    console.log(`üì± [CALLER-ID-MATCH] Customer Number: ${customerNumber}`)

    if (callType === "outbound") {
      console.log(`üîç [CALLER-ID-MATCH] Searched for callerId: "${agentIdentifier}"`)
      console.log(`‚úÖ [CALLER-ID-MATCH] Matched callerId: "${agentConfig.callerId}"`)
      console.log(`üéØ [CALLER-ID-MATCH] Connection Status: SUCCESSFUL - Agent "${agentConfig.agentName}" connected`)
    } else {
      console.log(`üîç [CALLER-ID-MATCH] Searched for accountSid: "${agentIdentifier}"`)
      console.log(`‚úÖ [CALLER-ID-MATCH] Matched accountSid: "${agentConfig.accountSid}"`)
      console.log(`üéØ [CALLER-ID-MATCH] Connection Status: SUCCESSFUL - Agent "${agentConfig.agentName}" connected`)
    }

    console.log(`üè∑Ô∏è  [CALLER-ID-MATCH] Agent Details:`)
    console.log(`   ‚Ä¢ Name: ${agentConfig.agentName}`)
    console.log(`   ‚Ä¢ Client ID: ${agentConfig.clientId}`)
    console.log(`   ‚Ä¢ Language: ${agentConfig.language}`)
    console.log(`   ‚Ä¢ Voice: ${agentConfig.voiceSelection}`)
    console.log(`   ‚Ä¢ Category: ${agentConfig.category}`)
    console.log(`üéØ [CALLER-ID-MATCH] ==========================================\n`)
  }
}

// MAIN: Enhanced WebSocket server setup with persistent Deepgram connections
const setupUnifiedVoiceServer = (wss) => {
  console.log("üöÄ [OPTIMIZED] Voice Server started with persistent Deepgram connections")

  wss.on("connection", (ws, req) => {
    const connectionTime = new Date()
    const clientIP = req.socket.remoteAddress

    console.log(`\nüîó [CONNECTION] ==========================================`)
    console.log(`üîó [CONNECTION] New optimized WebSocket connection`)
    console.log(`üåê [CONNECTION] Client IP: ${clientIP}`)
    console.log(`‚è∞ [CONNECTION] Time: ${connectionTime.toISOString()}`)
    console.log(`üì° [CONNECTION] User Agent: ${req.headers["user-agent"] || "unknown"}`)
    console.log(`üîó [CONNECTION] URL: ${req.url || "unknown"}`)

    // Parse SIP data from connection URL
    let sipData = null
    try {
      if (req.url) {
        console.log(`üîç [CONNECTION] Parsing URL for SIP parameters...`)
        sipData = SIPHeaderDecoder.parseConnectionURL(req.url)

        if (sipData) {
          console.log(`‚úÖ [CONNECTION] SIP parameters detected - this is a SIP call`)
          SIPHeaderDecoder.logSIPData(sipData)
          ws.sipData = sipData

          const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData)
          const callType = SIPHeaderDecoder.determineCallType(sipData)
          const agentIdentifier = SIPHeaderDecoder.getAgentIdentifier(sipData)

          console.log(`üéØ [CONNECTION] Call Analysis:`)
          console.log(`   ‚Ä¢ Customer Number: ${customerNumber}`)
          console.log(`   ‚Ä¢ Call Type: ${callType}`)
          console.log(`   ‚Ä¢ Agent Identifier: ${agentIdentifier}`)
          console.log(`   ‚Ä¢ DID: ${sipData.did}`)
          console.log(`   ‚Ä¢ Session ID: ${sipData.session_id}`)
        } else {
          console.log(`‚ÑπÔ∏è [CONNECTION] Non-SIP WebSocket connection (no SIP parameters found)`)
        }
      } else {
        console.log(`‚ÑπÔ∏è [CONNECTION] No URL provided in connection request`)
      }
    } catch (error) {
      console.log(`‚ÑπÔ∏è [CONNECTION] Error parsing URL for SIP data: ${error.message}`)
    }

    console.log(`üîó [CONNECTION] ==========================================\n`)

    // Session state
    let streamSid = null
    let conversationHistory = []
    let isProcessing = false
    let userUtteranceBuffer = ""
    let lastProcessedText = ""
    let optimizedTTS = null
    let currentLanguage = undefined
    let processingRequestId = 0
    let callLogger = null

    // OPTIMIZED: Single persistent Deepgram connection
    let deepgramManager = null

    // OPTIMIZED: Initialize persistent Deepgram manager
    const initializeDeepgramManager = (language, customerNumber) => {
      if (deepgramManager) {
        deepgramManager.cleanup()
      }

      deepgramManager = new PersistentDeepgramManager(
        language,
        async (transcript, is_final, confidence, type) => {
          await handleDeepgramResponse(transcript, is_final, confidence, type)
        },
        (error) => {
          console.error(`‚ùå [DEEPGRAM-MANAGER] Error for ${customerNumber}:`, error)
        },
        customerNumber,
      )

      return deepgramManager.connect()
    }

    // Enhanced Deepgram response handler
    const handleDeepgramResponse = async (transcript, is_final, confidence, type) => {
      const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"

      if (type === "utterance_end") {
        console.log(`üîö [DEEPGRAM-PERSISTENT] Utterance end detected for ${customerNumber}`)

        if (userUtteranceBuffer.trim()) {
          if (callLogger && userUtteranceBuffer.trim()) {
            const detectedLang = await detectLanguageWithOpenAI(userUtteranceBuffer.trim())
            callLogger.logUserTranscript(userUtteranceBuffer.trim(), detectedLang)

            console.log(
              `üìù [UTTERANCE-END] Customer (${customerNumber}): "${userUtteranceBuffer.trim()}" (${detectedLang})`,
            )
          }

          await processUserUtterance(userUtteranceBuffer)
          userUtteranceBuffer = ""
        }
        return
      }

      if (transcript?.trim()) {
        console.log(
          `üé§ [DEEPGRAM-PERSISTENT] ${is_final ? "FINAL" : "interim"} transcript from ${customerNumber}: "${transcript}" (confidence: ${confidence || "unknown"})`,
        )

        // Interrupt current TTS if new speech detected
        if (optimizedTTS && (isProcessing || optimizedTTS.isProcessing)) {
          console.log(`üõë [INTERRUPT] New speech from ${customerNumber} detected, interrupting current response`)
          optimizedTTS.interrupt()
          isProcessing = false
          processingRequestId++
        }

        if (is_final) {
          userUtteranceBuffer += (userUtteranceBuffer ? " " : "") + transcript.trim()

          if (callLogger && transcript.trim()) {
            const detectedLang = await detectLanguageWithOpenAI(transcript.trim())
            callLogger.logUserTranscript(transcript.trim(), detectedLang)

            console.log(`üìù [TRANSCRIPT] Customer (${customerNumber}): "${transcript.trim()}" (${detectedLang})`)
          }

          await processUserUtterance(userUtteranceBuffer)
          userUtteranceBuffer = ""
        }
      }
    }

    // Enhanced utterance processing with SIP context logging
    const processUserUtterance = async (text) => {
      if (!text.trim() || text === lastProcessedText) return

      if (optimizedTTS) {
        optimizedTTS.interrupt()
      }

      isProcessing = true
      lastProcessedText = text
      const currentRequestId = ++processingRequestId
      const timer = createTimer("UTTERANCE_PROCESSING")

      try {
        const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
        const callType = SIPHeaderDecoder.determineCallType(sipData)
        const agentName = ws.sessionAgentConfig?.agentName || "unknown"

        console.log(`\nüé§ [USER] ==========================================`)
        console.log(`üé§ [USER] Processing utterance from ${customerNumber}`)
        console.log(`üìû [USER] Call Type: ${callType}`)
        console.log(`ü§ñ [USER] Agent: ${agentName}`)
        console.log(`üìù [USER] Text: "${text}"`)
        console.log(`üìç [USER] DID: ${sipData?.did || "unknown"}`)
        console.log(`üÜî [USER] Session: ${sipData?.session_id || "unknown"}`)

        const detectedLanguage = await detectLanguageWithOpenAI(text)

        if (detectedLanguage !== currentLanguage) {
          console.log(`üåç [LANGUAGE] Changed: ${currentLanguage} ‚Üí ${detectedLanguage} for ${customerNumber}`)
          currentLanguage = detectedLanguage

          // Update Deepgram language if needed
          if (deepgramManager) {
            deepgramManager.updateLanguage(detectedLanguage)
          }
        }

        optimizedTTS = new OptimizedSarvamTTSProcessor(detectedLanguage, ws, streamSid, callLogger)

        const checkInterruption = () => {
          return processingRequestId !== currentRequestId
        }

        console.log(`ü§ñ [PROCESSING] Starting OpenAI processing for ${customerNumber}...`)

        const response = await processWithOpenAIStreaming(
          text,
          conversationHistory,
          detectedLanguage,
          (phrase, lang) => {
            if (processingRequestId === currentRequestId && !checkInterruption()) {
              console.log(`üì§ [PHRASE] "${phrase}" (${lang}) -> ${customerNumber}`)
              optimizedTTS.addPhrase(phrase, lang)
            }
          },
          (fullResponse) => {
            if (processingRequestId === currentRequestId && !checkInterruption()) {
              console.log(`‚úÖ [COMPLETE] "${fullResponse}" -> ${customerNumber}`)
              optimizedTTS.complete()

              const stats = optimizedTTS.getStats()
              console.log(
                `üìä [TTS-STATS] ${stats.totalChunks} chunks, ${stats.avgBytesPerChunk} avg bytes/chunk for ${customerNumber}`,
              )

              conversationHistory.push({ role: "user", content: text }, { role: "assistant", content: fullResponse })

              if (conversationHistory.length > 10) {
                conversationHistory = conversationHistory.slice(-10)
              }
            }
          },
          checkInterruption,
          callLogger,
        )

        console.log(`‚ö° [TOTAL] Processing completed in ${timer.end()}ms for ${customerNumber}`)
        console.log(`üé§ [USER] ==========================================\n`)
      } catch (error) {
        const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
        console.error(`‚ùå [PROCESSING] Error for ${customerNumber}: ${error.message}`)
        console.error(`‚ùå [PROCESSING] Stack trace:`, error.stack)
      } finally {
        if (processingRequestId === currentRequestId) {
          isProcessing = false
        }
      }
    }

    // Enhanced WebSocket message handling
    ws.on("message", async (message) => {
      try {
        if (!message || message.length === 0) {
          const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
          console.log(`‚ÑπÔ∏è [MESSAGE] Received empty message from ${customerNumber}`)
          return
        }

        let messageString
        try {
          messageString = message.toString()
          if (!messageString || messageString.trim() === "") {
            const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
            console.log(`‚ÑπÔ∏è [MESSAGE] Received empty string message from ${customerNumber}`)
            return
          }
        } catch (error) {
          console.log(`‚ö†Ô∏è [MESSAGE] Failed to convert message to string: ${error.message}`)
          return
        }

        const isBinaryData = /[\x00-\x08\x0E-\x1F\x7F-\xFF]/.test(messageString)

        if (isBinaryData || messageString.includes("\x00") || messageString.includes("ÔøΩÔøΩ")) {
          const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
          console.log(
            `üéµ [BINARY-DATA] Received binary audio data from ${customerNumber} (${messageString.length} bytes)`,
          )

          try {
            const audioBuffer = Buffer.from(message)
            console.log(
              `üéµ [AUDIO-STREAM] Processing raw audio buffer (${audioBuffer.length} bytes) from ${customerNumber}`,
            )

            if (deepgramManager) {
              const success = deepgramManager.sendAudio(audioBuffer)
              if (!success) {
                console.log(`‚ö†Ô∏è [AUDIO-STREAM] Failed to send audio to Deepgram for ${customerNumber}`)
              }
            } else {
              console.log(`‚ö†Ô∏è [AUDIO-STREAM] No Deepgram manager available for ${customerNumber}`)
            }
          } catch (audioError) {
            console.error(`‚ùå [AUDIO-STREAM] Error processing audio data from ${customerNumber}: ${audioError.message}`)
          }
          return
        }

        let data
        try {
          data = JSON.parse(messageString)
        } catch (jsonError) {
          const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"

          if (messageString.startsWith("<") || messageString.includes("HTTP/")) {
            console.log(
              `‚ÑπÔ∏è [MESSAGE] Received non-JSON message (likely HTTP/HTML) from ${customerNumber}: ${messageString.substring(0, 50)}...`,
            )
            return
          }

          if (messageString.includes("candidate") || messageString.includes("sdp")) {
            console.log(
              `‚ÑπÔ∏è [MESSAGE] Received WebRTC signaling data from ${customerNumber}: ${messageString.substring(0, 50)}...`,
            )
            return
          }

          if (messageString.includes("{") || messageString.includes("}")) {
            console.log(`‚ö†Ô∏è [MESSAGE] Partial/malformed JSON from ${customerNumber}: ${jsonError.message}`)
            console.log(`‚ö†Ô∏è [MESSAGE] Raw message (first 200 chars): "${messageString.substring(0, 200)}..."`)
          } else {
            console.log(`‚ö†Ô∏è [MESSAGE] Non-JSON message from ${customerNumber}: "${messageString.substring(0, 100)}..."`)
          }
          return
        }

        if (!data || typeof data !== "object" || !data.event) {
          const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
          console.log(`‚ö†Ô∏è [MESSAGE] Invalid message format from ${customerNumber}:`, data)
          return
        }

        let customerNumber

        switch (data.event) {
          case "connected":
            customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
            console.log(`üîó [OPTIMIZED] Connected from ${customerNumber} - Protocol: ${data.protocol}`)
            console.log(`üîó [OPTIMIZED] Version: ${data.version || "unknown"}`)
            break

          case "start": {
            streamSid = data.streamSid || data.start?.streamSid
            const accountSid = data.start?.accountSid
            customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData)
            const callType = SIPHeaderDecoder.determineCallType(sipData)

            console.log(`\nüéØ [OPTIMIZED] Stream started:`)
            console.log(`   ‚Ä¢ StreamSid: ${streamSid}`)
            console.log(`   ‚Ä¢ AccountSid: ${accountSid}`)
            console.log(`   ‚Ä¢ Customer Number: ${customerNumber}`)
            console.log(`   ‚Ä¢ Call Type: ${callType}`)

            if (sipData) {
              console.log(`   ‚Ä¢ SIP App ID: ${sipData.app_id}`)
              console.log(`   ‚Ä¢ SIP DID: ${sipData.did}`)
              console.log(`   ‚Ä¢ SIP Session ID: ${sipData.session_id}`)
              console.log(`   ‚Ä¢ SIP Direction: ${sipData.extra?.CallDirection || sipData.direction}`)
              console.log(`   ‚Ä¢ VA ID: ${sipData.extra?.CallVaId}`)
            }

            const fetchResult = await AgentConfigFetcher.fetchAgentConfig(sipData)

            if (!fetchResult.success) {
              console.error(`‚ùå [AGENT-CONFIG] ${fetchResult.error}`)

              const errorResponse = {
                event: "error",
                message: fetchResult.error,
                details: {
                  callType: fetchResult.callType,
                  agentIdentifier: fetchResult.agentIdentifier,
                  customerNumber: fetchResult.customerNumber,
                  sipData: sipData,
                },
              }

              ws.send(JSON.stringify(errorResponse))

              console.log(`üîå [AGENT-CONFIG] Closing connection due to missing agent configuration`)
              ws.close()
              return
            }

            const agentConfig = fetchResult.agentConfig
            const detectedCallType = fetchResult.callType

            AgentConfigFetcher.logCallerIdConnection(sipData, agentConfig)

            const validation = AgentConfigFetcher.validateAgentConfig(agentConfig)
            if (!validation.valid) {
              console.warn(`‚ö†Ô∏è [AGENT-VALIDATION] Agent configuration has issues but continuing...`)
            }

            console.log(`‚úÖ [AGENT-CONFIG] Successfully loaded for ${detectedCallType} call:`)
            console.log(`   ‚Ä¢ Client ID: ${agentConfig.clientId}`)
            console.log(`   ‚Ä¢ Agent Name: ${agentConfig.agentName}`)
            console.log(`   ‚Ä¢ Language: ${agentConfig.language}`)
            console.log(`   ‚Ä¢ Voice: ${agentConfig.voiceSelection}`)
            console.log(`   ‚Ä¢ STT: ${agentConfig.sttSelection}`)
            console.log(`   ‚Ä¢ TTS: ${agentConfig.ttsSelection}`)
            console.log(`   ‚Ä¢ LLM: ${agentConfig.llmSelection}`)

            if (detectedCallType === "outbound") {
              console.log(`   ‚Ä¢ Caller ID: ${agentConfig.callerId}`)
            } else {
              console.log(`   ‚Ä¢ Account SID: ${agentConfig.accountSid}`)
            }

            ws.sessionAgentConfig = agentConfig
            currentLanguage = agentConfig.language || "hi"

            callLogger = new CallLogger(agentConfig.clientId || accountSid, sipData)
            console.log(
              `üìù [CALL-LOG] Initialized for client: ${agentConfig.clientId}, customer: ${customerNumber}, call type: ${detectedCallType}`,
            )

            // OPTIMIZED: Initialize persistent Deepgram connection
            try {
              await initializeDeepgramManager(currentLanguage, customerNumber)
              console.log(`‚úÖ [DEEPGRAM-PERSISTENT] Manager initialized for ${customerNumber}`)
            } catch (deepgramError) {
              console.error(
                `‚ùå [DEEPGRAM-PERSISTENT] Failed to initialize manager for ${customerNumber}: ${deepgramError.message}`,
              )
            }

            console.log(`\nüéâ [CONNECTION-SUCCESS] ==========================================`)
            console.log(`‚úÖ [CONNECTION-SUCCESS] Agent "${agentConfig.agentName}" successfully connected!`)
            console.log(`üìû [CONNECTION-SUCCESS] Call Type: ${detectedCallType}`)
            console.log(`üì± [CONNECTION-SUCCESS] Customer: ${customerNumber}`)
            console.log(
              `üè∑Ô∏è  [CONNECTION-SUCCESS] Matched ID: ${detectedCallType === "outbound" ? agentConfig.callerId : agentConfig.accountSid}`,
            )
            console.log(`üéâ [CONNECTION-SUCCESS] ==========================================\n`)

            const greeting = agentConfig.firstMessage || "Hello! How can I help you today?"
            console.log(`üëã [GREETING] "${greeting}" -> ${customerNumber || "unknown customer"} (${detectedCallType})`)

            if (callLogger) {
              callLogger.logAIResponse(greeting, currentLanguage)
            }

            const tts = new OptimizedSarvamTTSProcessor(currentLanguage, ws, streamSid, callLogger)
            await tts.synthesizeAndStream(greeting)
            break
          }

          case "media":
            customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"

            if (data.media?.payload) {
              try {
                const audioBuffer = Buffer.from(data.media.payload, "base64")
                console.log(`üéµ [MEDIA] Received ${audioBuffer.length} bytes from ${customerNumber}`)

                if (deepgramManager) {
                  const success = deepgramManager.sendAudio(audioBuffer)
                  if (success) {
                    console.log(`üì§ [MEDIA] Sent to persistent Deepgram for ${customerNumber}`)
                  } else {
                    console.log(`‚ö†Ô∏è [MEDIA] Failed to send to Deepgram for ${customerNumber}`)
                  }
                } else {
                  console.log(`‚ö†Ô∏è [MEDIA] No Deepgram manager available for ${customerNumber}`)
                }
              } catch (mediaError) {
                console.error(`‚ùå [MEDIA] Error processing media from ${customerNumber}: ${mediaError.message}`)
              }
            } else {
              console.log(`‚ö†Ô∏è [MEDIA] No payload in media message from ${customerNumber}`)
            }
            break

          case "stop":
            customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
            const callType = SIPHeaderDecoder.determineCallType(sipData)
            console.log(`\nüìû [OPTIMIZED] Stream stopped for ${customerNumber} (${callType} call)`)

            if (callLogger) {
              try {
                const savedLog = await callLogger.saveToDatabase("completed")
                console.log(`üíæ [CALL-LOG] Final save completed - ID: ${savedLog._id}`)

                const stats = callLogger.getStats()
                console.log(`\nüìä [FINAL-STATS] Call Summary:`)
                console.log(`   ‚Ä¢ Duration: ${stats.duration}s`)
                console.log(`   ‚Ä¢ User Messages: ${stats.userMessages}`)
                console.log(`   ‚Ä¢ AI Responses: ${stats.aiResponses}`)
                console.log(`   ‚Ä¢ Languages: ${stats.languages.join(", ")}`)
                console.log(`   ‚Ä¢ Customer: ${customerNumber}`)
                console.log(`   ‚Ä¢ DID: ${sipData?.did || "unknown"}`)
                console.log(`   ‚Ä¢ Call Type: ${stats.callType}`)
                console.log(`   ‚Ä¢ Session ID: ${sipData?.session_id || "unknown"}`)

                if (sipData?.extra) {
                  console.log(`   ‚Ä¢ VA ID: ${sipData.extra.CallVaId || "unknown"}`)
                  console.log(`   ‚Ä¢ Service App ID: ${sipData.extra.CZSERVICEAPPID || "unknown"}`)
                }
              } catch (error) {
                console.error(`‚ùå [CALL-LOG] Failed to save final log: ${error.message}`)
              }
            }

            // OPTIMIZED: Cleanup persistent Deepgram connection
            if (deepgramManager) {
              deepgramManager.disconnect()
              console.log(`üîå [DEEPGRAM-PERSISTENT] Disconnected for ${customerNumber}`)
            }
            break

          case "mark":
            customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
            console.log(`üèÅ [MARK] Received mark event from ${customerNumber}: ${data.mark?.name || "unnamed"}`)
            break

          default:
            customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
            console.log(`‚ùì [OPTIMIZED] Unknown event: ${data.event} from ${customerNumber}`)
            console.log(`‚ùì [OPTIMIZED] Event data:`, JSON.stringify(data, null, 2))
        }
      } catch (error) {
        const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
        console.error(`‚ùå [OPTIMIZED] Unexpected error processing message from ${customerNumber}: ${error.message}`)
        console.error(`‚ùå [OPTIMIZED] Stack trace:`, error.stack)

        try {
          const messagePreview = message.toString().substring(0, 200)
          console.error(`‚ùå [OPTIMIZED] Problematic message preview: "${messagePreview}..."`)
        } catch (previewError) {
          console.error(`‚ùå [OPTIMIZED] Could not preview message: ${previewError.message}`)
        }
      }
    })

    // Enhanced connection cleanup with persistent Deepgram cleanup
    ws.on("close", async (code, reason) => {
      const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
      const callType = SIPHeaderDecoder.determineCallType(sipData)
      const agentName = ws.sessionAgentConfig?.agentName || "unknown"
      const connectionDuration = Date.now() - connectionTime.getTime()

      console.log(`\nüîó [DISCONNECT] ==========================================`)
      console.log(`üîó [DISCONNECT] Connection closed for ${customerNumber}`)
      console.log(`üìû [DISCONNECT] Call Type: ${callType}`)
      console.log(`ü§ñ [DISCONNECT] Agent: ${agentName}`)
      console.log(`‚è∞ [DISCONNECT] Connection Duration: ${Math.round(connectionDuration / 1000)}s`)
      console.log(`üî¢ [DISCONNECT] Close Code: ${code || "unknown"}`)
      console.log(`üìù [DISCONNECT] Close Reason: ${reason || "no reason provided"}`)

      if (sipData) {
        console.log(`üìç [DISCONNECT] DID: ${sipData.did}`)
        console.log(`üÜî [DISCONNECT] Session ID: ${sipData.session_id}`)
        console.log(`üè¢ [DISCONNECT] App ID: ${sipData.app_id}`)

        if (sipData.extra) {
          console.log(`üì± [DISCONNECT] VA ID: ${sipData.extra.CallVaId}`)
          console.log(`üîÑ [DISCONNECT] Call Direction: ${sipData.extra.CallDirection}`)
        }
      }

      if (callLogger) {
        try {
          console.log(`üíæ [DISCONNECT] Saving call log for ${customerNumber}...`)

          let disconnectReason = "disconnected"
          if (code === 1000) disconnectReason = "normal_closure"
          else if (code === 1001) disconnectReason = "going_away"
          else if (code === 1006) disconnectReason = "abnormal_closure"
          else if (code === 1011) disconnectReason = "server_error"

          const savedLog = await callLogger.saveToDatabase(disconnectReason)

          console.log(`‚úÖ [DISCONNECT] Call log saved successfully`)
          console.log(`   ‚Ä¢ Log ID: ${savedLog._id}`)
          console.log(`   ‚Ä¢ Customer: ${customerNumber}`)
          console.log(`   ‚Ä¢ Agent: ${agentName}`)
          console.log(`   ‚Ä¢ Call Type: ${callType}`)
          console.log(`   ‚Ä¢ Status: ${disconnectReason}`)

          const stats = callLogger.getStats()
          console.log(`üìä [DISCONNECT] Final Call Statistics:`)
          console.log(`   ‚Ä¢ Total Duration: ${stats.duration}s`)
          console.log(`   ‚Ä¢ User Messages: ${stats.userMessages}`)
          console.log(`   ‚Ä¢ AI Responses: ${stats.aiResponses}`)
          console.log(`   ‚Ä¢ Languages Used: ${stats.languages.join(", ")}`)
          console.log(`   ‚Ä¢ Customer Number: ${stats.customerNumber}`)
          console.log(`   ‚Ä¢ Call Type: ${stats.callType}`)
        } catch (error) {
          console.error(`‚ùå [DISCONNECT] Failed to save call log for ${customerNumber}: ${error.message}`)
          console.error(`‚ùå [DISCONNECT] Call log error details:`, error.stack)
        }
      } else {
        console.log(`‚ÑπÔ∏è [DISCONNECT] No call logger instance found for ${customerNumber}`)
      }

      // OPTIMIZED: Cleanup persistent Deepgram connection
      if (deepgramManager) {
        console.log(`üîå [DISCONNECT] Cleaning up persistent Deepgram connection for ${customerNumber}`)
        deepgramManager.cleanup()

        const status = deepgramManager.getStatus()
        console.log(
          `üìä [DISCONNECT] Final Deepgram status: Connected: ${status.isConnected}, Queue: ${status.queueSize}, Reconnects: ${status.reconnectAttempts}`,
        )
      } else {
        console.log(`‚ÑπÔ∏è [DISCONNECT] No Deepgram manager found for ${customerNumber}`)
      }

      if (optimizedTTS) {
        console.log(`üîä [DISCONNECT] Interrupting TTS processor for ${customerNumber}`)
        optimizedTTS.interrupt()
      }

      // Reset all state variables
      streamSid = null
      conversationHistory = []
      isProcessing = false
      userUtteranceBuffer = ""
      lastProcessedText = ""
      optimizedTTS = null
      currentLanguage = undefined
      processingRequestId = 0
      callLogger = null
      deepgramManager = null

      console.log(`üßπ [DISCONNECT] Cleaned up all session data for ${customerNumber}`)
      console.log(`üîó [DISCONNECT] ==========================================\n`)
    })

    ws.on("error", (error) => {
      const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
      const callType = SIPHeaderDecoder.determineCallType(sipData)
      const agentName = ws.sessionAgentConfig?.agentName || "unknown"

      console.log(`\n‚ùå [ERROR] ==========================================`)
      console.error(`‚ùå [ERROR] WebSocket error for ${customerNumber}`)
      console.error(`üìû [ERROR] Call Type: ${callType}`)
      console.error(`ü§ñ [ERROR] Agent: ${agentName}`)
      console.error(`üìù [ERROR] Error Message: ${error.message}`)
      console.error(`üîç [ERROR] Error Code: ${error.code || "unknown"}`)

      if (sipData) {
        console.error(`üìç [ERROR] DID: ${sipData.did}`)
        console.error(`üÜî [ERROR] Session ID: ${sipData.session_id}`)
      }

      console.error(`üìö [ERROR] Stack Trace:`, error.stack)
      console.log(`‚ùå [ERROR] ==========================================\n`)

      if (callLogger) {
        callLogger.saveToDatabase("error").catch((logError) => {
          console.error(`‚ùå [ERROR] Failed to save emergency call log: ${logError.message}`)
        })
      }

      // OPTIMIZED: Cleanup Deepgram on error
      if (deepgramManager) {
        console.log(`üîå [ERROR] Cleaning up Deepgram manager due to error for ${customerNumber}`)
        deepgramManager.cleanup()
      }
    })

    // Optional: Add ping/pong heartbeat for connection monitoring
    const heartbeatInterval = setInterval(() => {
      if (ws.readyState === WebSocket.OPEN) {
        const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
        console.log(`üíì [HEARTBEAT] Connection alive for ${customerNumber}`)

        // Also check Deepgram status
        if (deepgramManager) {
          const status = deepgramManager.getStatus()
          console.log(
            `üíì [HEARTBEAT] Deepgram status for ${customerNumber}: Connected: ${status.isConnected}, Queue: ${status.queueSize}`,
          )
        }

        ws.ping()
      } else {
        clearInterval(heartbeatInterval)
      }
    }, 30000)

    ws.on("pong", () => {
      const customerNumber = SIPHeaderDecoder.getCustomerNumber(sipData) || "unknown"
      console.log(`üíì [PONG] Heartbeat response from ${customerNumber}`)
    })

    ws.on("close", () => {
      clearInterval(heartbeatInterval)
    })
  })
}

module.exports = {
  setupUnifiedVoiceServer,
  SIPHeaderDecoder,
  CallLogger,
  AgentConfigFetcher,
  PersistentDeepgramManager,
}
